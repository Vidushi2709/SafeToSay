# SafeToSay - Clinical AI Agent System

### A Multi-Agent Clinical Q&A System That Knows When *Not* to Answer

---

Most medical LLMs answer everything.

**MedGemma doesnâ€™t.**

MedGemma is a multi-agent clinical guideline assistant that evaluates safety and evidence *before* responding. If a query is unsafe, out-of-scope, or insufficiently supported by evidence, the system **explicitly abstains**.

Evaluation isnâ€™t a metric after generation â€”
**evaluation is the system.**

Built with LangGraph orchestration, MedGemma 4B for medical generation, Mistral AI for reasoning agents, and Tavily for real-time medical literature retrieval.

---

## ğŸ¯ Problem

Clinical AI systems often:

* Over-answer
* Hallucinate evidence
* Provide patient-specific advice
* Fail to abstain under uncertainty

In medicine, **not answering can be safer than answering poorly.**

---

## ğŸ§  Core Idea

Instead of relying on a single model with safety prompting, MedGemma uses:

* âœ… Specialized agents with narrow responsibilities
* âœ… Runtime evaluation before release
* âœ… Deterministic decision gating
* âœ… Explicit abstention logic
* âœ… Real-time evidence retrieval

The system either:

* âœ”ï¸ Provides evidence-grounded guidance
* âš ï¸ Returns a constrained partial answer
* âŒ Explicitly abstains

---

## ğŸ‘¥ Target Use Case

Guideline-based Q&A for healthcare professionals:

* Junior doctors
* Nurses
* Physician assistants

### âœ… Allowed

* Contraindications
* Eligibility criteria
* Guideline clarifications
* Medication interactions
* Protocol explanations

### âŒ Disallowed

* Diagnosis
* Treatment recommendations
* Patient-specific decisions
* Emergency medical advice

---

# ğŸ—ï¸ System Architecture

```
User Query
     â†“
Scope & Intent Agent
     â†“
Knowledge Boundary Agent
     â†“
Medical Evidence Retrieval (Tavily)
     â†“
Answer Generation (MedGemma 4B)
     â†“
Evaluation Agent (5-metric audit)
     â†“
Deterministic Decision Gate
     â†“
ANSWER | PARTIAL | ABSTAIN
```

---

# ğŸ¤– Agent Design

## 1ï¸âƒ£ Scope & Intent Agent (Mistral AI)

Filters unsafe queries early.

Outputs:

* `IN_SCOPE` / `OUT_OF_SCOPE`
* Intent classification
* Risk flags

Example:

* "Can NSAIDs be given with aspirin?" â†’ IN_SCOPE
* "Diagnose my chest pain" â†’ OUT_OF_SCOPE

---

## 2ï¸âƒ£ Knowledge Boundary Agent (Mistral AI)

Identifies knowledge gaps and confidence limits.

Outputs:

* Required domains
* Knowledge gaps
* Confidence risk (LOW / MEDIUM / HIGH)

Prevents overconfident generation when information is insufficient.

---

## 3ï¸âƒ£ Answer Generation Agent (MedGemma 4B)

Generates structured, evidence-constrained clinical answers.

* Model: `google/medgemma-4b-it`
* 4-bit quantized (BitsAndBytes)
* Deterministic decoding
* Grounded in retrieved evidence

---

## 4ï¸âƒ£ Evaluation Agent (Mistral AI)

Audits the draft before release.

Scores (1â€“5):

* Evidence Support
* Missing Preconditions
* Overconfidence
* Contradictions
* Scope Violation

Detects critical failures automatically.

---

## 5ï¸âƒ£ Deterministic Decision Gate

Final logic layer:

* **ANSWER** â†’ All scores â‰¥ 3
* **PARTIAL** â†’ Minor weakness, no critical failure
* **ABSTAIN** â†’ Any major failure or critical violation

This makes the system auditable and transparent.

---

# ğŸ” Evidence Retrieval (Tavily)

Real-time medical search across:

* PubMed
* NIH
* WHO
* Mayo Clinic
* WebMD
* UpToDate
* Up to 5 sources per query
* Source URLs included in output
* Medical-domain filtering enabled

---

# ğŸ› ï¸ Tech Stack

### Backend

* Python 3.10+
* FastAPI (SSE streaming)
* LangGraph (multi-agent orchestration)
* LangChain
* Mistral AI (reasoning agents)
* MedGemma 4B (generation)
* PyTorch + Transformers
* BitsAndBytes (4-bit quantization)
* Tavily (medical search)

### Frontend

* React 18
* Tailwind CSS
* Server-Sent Events (real-time agent tracing)

---

# âš™ï¸ Installation

### 1ï¸âƒ£ Clone

```bash
git clone <repo-url>
cd SafeToSay
```

### 2ï¸âƒ£ Backend Setup

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate (Windows)
pip install -r requirements.txt
```

Create `.env`:

```
MISTRAL_API_KEY=your_key
TAVILY_API_KEY=your_key
```

Run backend:

```bash
python api_server.py
```

---

### 3ï¸âƒ£ Frontend Setup

```bash
cd frontend
npm install
npm start
```

---

# ğŸ’¬ Demo Flow

Ask:

* "What are contraindications for beta-blockers?"
* "Can NSAIDs worsen kidney function?"
* "What are eligibility criteria for statin therapy?"

Watch the pipeline execute:

* Scope analysis
* Knowledge boundary check
* Evidence retrieval
* Draft generation
* Safety audit
* Final decision

If unsafe:

The system abstains clearly and transparently.

---

# ğŸ“ What This Demonstrates

* Runtime evaluation-in-the-loop
* Self-checking multi-agent systems
* Deterministic safety gating
* Evidence-grounded reasoning
* Transparent abstention logic

Rather than maximizing response rate, the system optimizes **decision quality and safety**.

---

# ğŸ”’ Limitations

* Not for emergency decisions
* Not a replacement for clinical judgment
* Restricted to guideline-based Q&A
* Research prototype only

---

# ğŸ§ª Why This Matters

In clinical AI, correctness is important.

But knowing when not to answer
may be more important.

MedGemma prioritizes safe abstention over unsafe confidence.

---
# â­ Contribution 

if you like it, feel free to take it, make it better. 

